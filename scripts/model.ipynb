{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 15:01:57,392 - Chargement des métadonnées fusionnées depuis balanced_data.pkl\n",
      "2025-01-29 15:01:57,398 - Filtrage des données pour inclure uniquement les colonnes requises et non nulles.\n",
      "2025-01-29 15:01:57,406 - Nombre total d'images après filtrage : 948\n",
      "2025-01-29 15:01:57,409 - Division des données en ensembles d'entraînement et de validation.\n",
      "2025-01-29 15:01:57,415 - Nombre d'images pour l'entraînement : 758\n",
      "2025-01-29 15:01:57,415 - Nombre d'images pour la validation : 190\n",
      "2025-01-29 15:01:57,468 - Définition du modèle EfficientNetB0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    316\n",
      "2    316\n",
      "0    316\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 15:01:58,406 - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "2025-01-29 15:01:58,408 - There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "2025-01-29 15:01:58,413 - Début de l'entraînement du modèle (phase 1).\n",
      "2025-01-29 15:01:58,421 - Traitement du batch 1/24: 32 images.\n",
      "2025-01-29 15:02:10,530 - Batch 1 chargé : 32 images valides.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 226\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m# ====================  \u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# ENTRAÎNEMENT - PHASE 1\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# ====================\u001b[39;00m\n\u001b[1;32m    224\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDébut de l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentraînement du modèle (phase 1).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 226\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgen_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS_INITIAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 30\u001b[39;49;00m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    232\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhase 1 d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentraînement terminée. Début du fine-tuning.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# ====================\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# FINE-TUNING - PHASE 2\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# ====================\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:890\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[0;32m--> 890\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    892\u001b[0m   _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    893\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn\u001b[38;5;241m.\u001b[39m_function_spec  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    894\u001b[0m       \u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(\n\u001b[1;32m    895\u001b[0m           args, kwds))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:180\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls this function with `args` as inputs.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m  `ConcreteFunction` execution respects device annotations only if the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m      available to be called because it has been garbage collected.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcached_definition\u001b[49m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39minput_arg):\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSignature specifies\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached_definition\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39minput_arg))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m     )\n\u001b[1;32m    187\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:139\u001b[0m, in \u001b[0;36mAtomicFunction.cached_definition\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Cached FunctionDef (not guaranteed to be fresh).\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_definition \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_definition \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefinition\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_definition\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:132\u001b[0m, in \u001b[0;36mAtomicFunction.definition\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefinition\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Current FunctionDef in the Runtime.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_function_def\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1389\u001b[0m, in \u001b[0;36mContext.get_function_def\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1387\u001b[0m   proto_data \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(buffer_)\n\u001b[1;32m   1388\u001b[0m function_def \u001b[38;5;241m=\u001b[39m function_pb2\u001b[38;5;241m.\u001b[39mFunctionDef()\n\u001b[0;32m-> 1389\u001b[0m \u001b[43mfunction_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParseFromString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproto_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function_def\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Configuration des logs\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# ====================\n",
    "# PARAMÈTRES GÉNÉRAUX\n",
    "# ====================\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Nombre d’époques\n",
    "EPOCHS_INITIAL = 30  # Phase 1\n",
    "EPOCHS_FINE = 10     # Phase 2\n",
    "\n",
    "LEARNING_RATE_INITIAL = 1e-4\n",
    "LEARNING_RATE_FINE = 1e-5\n",
    "\n",
    "# Chemin vers le fichier pickle\n",
    "NOTEBOOK_DIRECTORY = \"/Users/dtilm/Desktop/P1-Classification/notebook/balanced_data.pkl\"\n",
    "\n",
    "\n",
    "# ====================\n",
    "# CHARGEMENT DES DONNÉES\n",
    "# ====================\n",
    "logger.info(\"Chargement des métadonnées fusionnées depuis balanced_data.pkl\")\n",
    "balanced_data = pd.read_pickle(NOTEBOOK_DIRECTORY)\n",
    "\n",
    "# Filtrage des données pour inclure uniquement les colonnes requises et non nulles\n",
    "logger.info(\"Filtrage des données pour inclure uniquement les colonnes requises et non nulles.\")\n",
    "filtered_data = balanced_data[\n",
    "    [\n",
    "        'image_file_path_dicom',\n",
    "        'pathology',\n",
    "        'abnormality_type',\n",
    "        'left_or_right_breast',\n",
    "        'image_view'\n",
    "    ]\n",
    "].dropna()\n",
    "\n",
    "label_mapping = {'BENIGN_WITHOUT_CALLBACK': 0, 'BENIGN': 1, 'MALIGNANT': 2}\n",
    "filtered_data['label'] = filtered_data['pathology'].map(label_mapping)\n",
    "\n",
    "logger.info(f\"Nombre total d'images après filtrage : {len(filtered_data)}\")\n",
    "print(filtered_data['label'].value_counts())\n",
    "\n",
    "logger.info(\"Division des données en ensembles d'entraînement et de validation.\")\n",
    "train_data, val_data = train_test_split(\n",
    "    filtered_data, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=filtered_data['label']\n",
    ")\n",
    "\n",
    "train_paths = train_data['image_file_path_dicom'].tolist()\n",
    "train_labels = train_data['label'].tolist()\n",
    "val_paths = val_data['image_file_path_dicom'].tolist()\n",
    "val_labels = val_data['label'].tolist()\n",
    "\n",
    "logger.info(f\"Nombre d'images pour l'entraînement : {len(train_paths)}\")\n",
    "logger.info(f\"Nombre d'images pour la validation : {len(val_paths)}\")\n",
    "\n",
    "\n",
    "# ====================\n",
    "# DATA AUGMENTATION\n",
    "# ====================\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomRotation(0.05),\n",
    "    layers.RandomZoom(0.1, 0.1),\n",
    "])\n",
    "\n",
    "# ====================\n",
    "# FONCTION DE PRÉTRAITEMENT\n",
    "# ====================\n",
    "def preprocess_dicom(file_path):\n",
    "    try:\n",
    "        dicom = pydicom.dcmread(file_path, force=True)\n",
    "        img = dicom.pixel_array.astype(np.float32)\n",
    "\n",
    "        img -= np.min(img)\n",
    "        max_val = np.max(img)\n",
    "        if max_val == 0:\n",
    "            return None\n",
    "        img = (img / max_val) * 255.0\n",
    "\n",
    "        img = np.stack([img, img, img], axis=-1)\n",
    "        img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        img = preprocess_input(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur DICOM {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ====================\n",
    "# EXEMPLE VISUEL (OPTIONNEL)\n",
    "# ====================\n",
    "def show_random_preprocessed_images(paths, num_images=5):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for i in range(num_images):\n",
    "        path = random.choice(paths)\n",
    "        preprocessed_img = preprocess_dicom(path)\n",
    "        if preprocessed_img is not None:\n",
    "            preprocessed_img_np = preprocessed_img.numpy()\n",
    "            min_val = preprocessed_img_np.min()\n",
    "            max_val = preprocessed_img_np.max()\n",
    "            if max_val > min_val:\n",
    "                disp_img = (preprocessed_img_np - min_val) / (max_val - min_val)\n",
    "            else:\n",
    "                disp_img = preprocessed_img_np\n",
    "            plt.subplot(1, num_images, i + 1)\n",
    "            plt.imshow(disp_img)\n",
    "            plt.title(f\"Sample {i+1}\")\n",
    "            plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# show_random_preprocessed_images(train_paths, num_images=5)\n",
    "\n",
    "# ====================\n",
    "# GÉNÉRATEURS DE DONNÉES\n",
    "# ====================\n",
    "class DICOMDataGenerator(Sequence):\n",
    "    def __init__(self, file_paths, labels, batch_size, augment=False, shuffle=True):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augment\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            indices = np.arange(len(self.file_paths))\n",
    "            np.random.shuffle(indices)\n",
    "            self.file_paths = [self.file_paths[i] for i in indices]\n",
    "            self.labels = [self.labels[i] for i in indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.file_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_paths = self.file_paths[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        batch_labels = self.labels[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "\n",
    "        logger.info(f\"Traitement du batch {idx + 1}/{self.__len__()}: {len(batch_paths)} images.\")\n",
    "\n",
    "        images = []\n",
    "        valid_labels = []\n",
    "\n",
    "        for path, lbl in zip(batch_paths, batch_labels):\n",
    "            img = preprocess_dicom(path)\n",
    "            if img is not None:\n",
    "                if self.augment:\n",
    "                    img = tf.expand_dims(img, 0)\n",
    "                    img = data_augmentation(img)\n",
    "                    img = tf.squeeze(img, axis=0)\n",
    "                images.append(img)\n",
    "                valid_labels.append(lbl)\n",
    "\n",
    "        images = np.array(images)\n",
    "        labels_array = np.array(valid_labels)\n",
    "\n",
    "        logger.info(f\"Batch {idx + 1} chargé : {len(images)} images valides.\")\n",
    "        return images, tf.keras.utils.to_categorical(labels_array, num_classes=3)\n",
    "\n",
    "gen_train = DICOMDataGenerator(train_paths, train_labels, BATCH_SIZE, augment=True, shuffle=True)\n",
    "gen_val = DICOMDataGenerator(val_paths, val_labels, BATCH_SIZE, augment=False, shuffle=False)\n",
    "\n",
    "# ====================\n",
    "# CONSTRUCTION DU MODÈLE\n",
    "# ====================\n",
    "logger.info(\"Définition du modèle EfficientNetB0.\")\n",
    "\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# Phase 1 : on gèle le backbone\n",
    "base_model.trainable = False\n",
    "\n",
    "# --- AMÉLIORATION : COUCHE DENSE CACHÉE ---\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.5),\n",
    "    # nouvelle couche dense\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(3, activation='softmax')  # sortie\n",
    "])\n",
    "\n",
    "# Compilation initiale (phase 1)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_INITIAL),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ====================\n",
    "# CALLBACKS\n",
    "# ====================\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "]\n",
    "\n",
    "# ====================  \n",
    "# ENTRAÎNEMENT - PHASE 1\n",
    "# ====================\n",
    "logger.info(\"Début de l'entraînement du modèle (phase 1).\")\n",
    "\n",
    "history = model.fit(\n",
    "    gen_train,\n",
    "    validation_data=gen_val,\n",
    "    epochs=EPOCHS_INITIAL,  # 30\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "logger.info(\"Phase 1 d'entraînement terminée. Début du fine-tuning.\")\n",
    "\n",
    "# ====================\n",
    "# FINE-TUNING - PHASE 2\n",
    "# ====================\n",
    "nb_layers = len(base_model.layers)\n",
    "# On dé-gèle 50 % des couches finales du backbone\n",
    "for layer in base_model.layers[-int(nb_layers * 0.5):]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_FINE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_fine = model.fit(\n",
    "    gen_train,\n",
    "    validation_data=gen_val,\n",
    "    epochs=EPOCHS_FINE,  # 10\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "logger.info(\"Fine-tuning terminé. Sauvegarde du modèle.\")\n",
    "\n",
    "model.save('efficientnet_b0_updated_multiclass.h5')\n",
    "logger.info(\"Modèle sauvegardé avec succès.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 13:38:58,565 - Loading data...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "issubclass() arg 1 must be a class",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/pickle.py:202\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    201\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mWarning\u001b[39;00m)\n\u001b[0;32m--> 202\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/_core/numeric.py:1924\u001b[0m, in \u001b[0;36m_frombuffer\u001b[0;34m(buf, dtype, shape, order)\u001b[0m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_frombuffer\u001b[39m(buf, dtype, shape, order):\n\u001b[0;32m-> 1924\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrombuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(shape, order\u001b[38;5;241m=\u001b[39morder)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret 'dtype('float64')' as a data type",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/compat/pickle_compat.py:35\u001b[0m, in \u001b[0;36mload_reduce\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m     stack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/_core/numeric.py:1924\u001b[0m, in \u001b[0;36m_frombuffer\u001b[0;34m(buf, dtype, shape, order)\u001b[0m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_frombuffer\u001b[39m(buf, dtype, shape, order):\n\u001b[0;32m-> 1924\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrombuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(shape, order\u001b[38;5;241m=\u001b[39morder)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret 'dtype('float64')' as a data type",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 319\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m history, history_fine\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 319\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 201\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m# Load and prepare data\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 201\u001b[0m     balanced_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNOTEBOOK_DIRECTORY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# Filter data\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     filtered_data \u001b[38;5;241m=\u001b[39m balanced_data[\n\u001b[1;32m    205\u001b[0m         [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_file_path_dicom\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpathology\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabnormality_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m    206\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft_or_right_breast\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_view\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    207\u001b[0m     ]\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/pickle.py:207\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pc\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/compat/pickle_compat.py:231\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# \"Unpickler\" has no attribute \"is_verbose\"  [attr-defined]\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     up\u001b[38;5;241m.\u001b[39mis_verbose \u001b[38;5;241m=\u001b[39m is_verbose  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1213\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/compat/pickle_compat.py:55\u001b[0m, in \u001b[0;36mload_reduce\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m     stack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43missubclass\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPeriodArray\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     57\u001b[0m     stack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m NDArrayBacked\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[0;31mTypeError\u001b[0m: issubclass() arg 1 must be a class"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.applications import EfficientNetB2\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Configuration des logs\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# ====================\n",
    "# PARAMÈTRES GÉNÉRAUX\n",
    "# ====================\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16  # Reduced batch size for better generalization\n",
    "EPOCHS_INITIAL = 40  # Increased epochs for better learning\n",
    "EPOCHS_FINE = 20    # More fine-tuning epochs\n",
    "\n",
    "# Chemin vers le fichier pickle\n",
    "NOTEBOOK_DIRECTORY = \"/Users/dtilm/Desktop/P1-Classification/notebook/balanced_data.pkl\"\n",
    "\n",
    "# ====================\n",
    "# PREPROCESSING FUNCTIONS\n",
    "# ====================\n",
    "def enhance_mammogram(img):\n",
    "    \"\"\"\n",
    "    Enhance mammogram image using CLAHE and percentile normalization\n",
    "    \"\"\"\n",
    "    # Normalize to 0-255 range\n",
    "    if img.dtype != np.uint8:\n",
    "        p5 = np.percentile(img, 5)\n",
    "        p95 = np.percentile(img, 95)\n",
    "        img = np.clip(img, p5, p95)\n",
    "        img = ((img - p5) / (p95 - p5) * 255).astype(np.uint8)\n",
    "    \n",
    "    # Apply CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(img)\n",
    "    \n",
    "    return enhanced\n",
    "\n",
    "def preprocess_dicom(file_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess DICOM image with enhanced normalization and CLAHE\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dicom = pydicom.dcmread(file_path, force=True)\n",
    "        img = dicom.pixel_array.astype(np.float32)\n",
    "        \n",
    "        # Enhanced normalization\n",
    "        img = enhance_mammogram(img)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Convert to 3 channels\n",
    "        img = np.stack([img, img, img], axis=-1)\n",
    "        img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        return img\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur DICOM {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ====================\n",
    "# DATA AUGMENTATION\n",
    "# ====================\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomFlip(mode=\"horizontal\"),\n",
    "    layers.RandomBrightness(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "])\n",
    "\n",
    "\n",
    "def create_learning_rate_scheduler(warmup_epochs, initial_lr, total_epochs, steps_per_epoch):\n",
    "    \"\"\"\n",
    "    Creates a learning rate schedule with warmup and cosine decay\n",
    "    \"\"\"\n",
    "    warmup_steps = warmup_epochs * steps_per_epoch\n",
    "    total_steps = total_epochs * steps_per_epoch\n",
    "    \n",
    "    def scheduler(epoch, lr):\n",
    "        step = epoch * steps_per_epoch\n",
    "        # Warmup phase\n",
    "        if step < warmup_steps:\n",
    "            return (step / warmup_steps) * initial_lr\n",
    "        # Cosine decay phase\n",
    "        else:\n",
    "            progress = (step - warmup_steps) / (total_steps - warmup_steps)\n",
    "            return initial_lr * 0.5 * (1 + np.cos(np.pi * progress))\n",
    "    \n",
    "    return tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "# ====================\n",
    "# DATA GENERATOR\n",
    "# ====================\n",
    "class DICOMDataGenerator(Sequence):\n",
    "    def __init__(self, file_paths, labels, batch_size, augment=False, shuffle=True):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augment\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            indices = np.arange(len(self.file_paths))\n",
    "            np.random.shuffle(indices)\n",
    "            self.file_paths = [self.file_paths[i] for i in indices]\n",
    "            self.labels = [self.labels[i] for i in indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.file_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_paths = self.file_paths[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        batch_labels = self.labels[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "\n",
    "        images = []\n",
    "        valid_labels = []\n",
    "\n",
    "        for path, lbl in zip(batch_paths, batch_labels):\n",
    "            img = preprocess_dicom(path)\n",
    "            if img is not None:\n",
    "                if self.augment:\n",
    "                    img = tf.expand_dims(img, 0)\n",
    "                    img = data_augmentation(img)\n",
    "                    img = tf.squeeze(img, axis=0)\n",
    "                images.append(img)\n",
    "                valid_labels.append(lbl)\n",
    "\n",
    "        images = np.array(images)\n",
    "        labels_array = np.array(valid_labels)\n",
    "\n",
    "        return images, tf.keras.utils.to_categorical(labels_array, num_classes=3)\n",
    "\n",
    "# ====================\n",
    "# MODEL ARCHITECTURE\n",
    "# ====================\n",
    "def build_improved_model(img_size=224):\n",
    "    \"\"\"\n",
    "    Creates an improved model based on EfficientNetB2 with custom head\n",
    "    \"\"\"\n",
    "    base_model = EfficientNetB2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(img_size, img_size, 3)\n",
    "    )\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ====================\n",
    "# FINE-TUNING HELPERS\n",
    "# ====================\n",
    "def apply_fine_tuning(model, unfreeze_percentage=0.3):\n",
    "    \"\"\"\n",
    "    Applies fine-tuning strategy by unfreezing last X% of layers\n",
    "    \"\"\"\n",
    "    base_model = model.layers[0]\n",
    "    nb_layers = len(base_model.layers)\n",
    "    \n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    for layer in base_model.layers[-int(nb_layers * unfreeze_percentage):]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    return model\n",
    "\n",
    "# ====================\n",
    "# MAIN TRAINING SCRIPT\n",
    "# ====================\n",
    "def main():\n",
    "    # Load and prepare data\n",
    "    logger.info(\"Loading data...\")\n",
    "    balanced_data = pd.read_pickle(NOTEBOOK_DIRECTORY)\n",
    "    \n",
    "    # Filter data\n",
    "    filtered_data = balanced_data[\n",
    "        ['image_file_path_dicom', 'pathology', 'abnormality_type', \n",
    "         'left_or_right_breast', 'image_view']\n",
    "    ].dropna()\n",
    "    \n",
    "    # Create labels\n",
    "    label_mapping = {'BENIGN_WITHOUT_CALLBACK': 0, 'BENIGN': 1, 'MALIGNANT': 2}\n",
    "    filtered_data['label'] = filtered_data['pathology'].map(label_mapping)\n",
    "    \n",
    "    # Split data\n",
    "    train_data, val_data = train_test_split(\n",
    "        filtered_data, \n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        stratify=filtered_data['label']\n",
    "    )\n",
    "    \n",
    "    # Create generators\n",
    "    gen_train = DICOMDataGenerator(\n",
    "        train_data['image_file_path_dicom'].tolist(),\n",
    "        train_data['label'].tolist(),\n",
    "        BATCH_SIZE,\n",
    "        augment=True,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    gen_val = DICOMDataGenerator(\n",
    "        val_data['image_file_path_dicom'].tolist(),\n",
    "        val_data['label'].tolist(),\n",
    "        BATCH_SIZE,\n",
    "        augment=False,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Create callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            mode='max'\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_accuracy',\n",
    "            factor=0.7,\n",
    "            patience=5,\n",
    "            verbose=1,\n",
    "            mode='max'\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            'best_model.keras',  # Changed from .h5 to .keras\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max'\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Build and compile model\n",
    "    logger.info(\"Building model...\")\n",
    "    model = build_improved_model(IMG_SIZE)\n",
    "    \n",
    "    # Initial training phase\n",
    "    logger.info(\"Starting initial training phase...\")\n",
    "    initial_lr = 2e-4\n",
    "\n",
    "    # Add LR scheduler to callbacks\n",
    "    lr_scheduler = create_learning_rate_scheduler(\n",
    "        warmup_epochs=5,\n",
    "        initial_lr=initial_lr,\n",
    "        total_epochs=EPOCHS_INITIAL,\n",
    "        steps_per_epoch=len(gen_train)\n",
    "    )\n",
    "    callbacks.append(lr_scheduler)\n",
    "\n",
    "    # Use constant initial learning rate for optimizer\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=initial_lr),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        gen_train,\n",
    "        validation_data=gen_val,\n",
    "        epochs=EPOCHS_INITIAL,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Fine-tuning phase\n",
    "    logger.info(\"Starting fine-tuning phase...\")\n",
    "    model = apply_fine_tuning(model)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    history_fine = model.fit(\n",
    "        gen_train,\n",
    "        validation_data=gen_val,\n",
    "        epochs=EPOCHS_FINE,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Save final model\n",
    "    logger.info(\"Saving final model...\")\n",
    "    model.save('final_model.keras')\n",
    "    \n",
    "    return history, history_fine\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 16:14:19,044 - Loading data...\n",
      "2025-01-29 16:14:19,062 - Building model...\n",
      "2025-01-29 16:14:19,732 - Starting training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "69/95 [====================>.........] - ETA: 43s - loss: 2.4230 - accuracy: 0.3382"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 307\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m history\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 307\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 293\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    264\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    265\u001b[0m     EarlyStopping(\n\u001b[1;32m    266\u001b[0m         monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    289\u001b[0m     )\n\u001b[1;32m    290\u001b[0m ]\n\u001b[1;32m    292\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 293\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgen_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS_INITIAL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    302\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# ====================\n",
    "# OPTIMIZED PARAMETERS\n",
    "# ====================\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS_INITIAL = 40\n",
    "INITIAL_LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-3\n",
    "WARMUP_EPOCHS = 2\n",
    "\n",
    "# Chemin vers le fichier pickle\n",
    "NOTEBOOK_DIRECTORY = \"/Users/dtilm/Desktop/P1-Classification/notebook/balanced_data.pkl\"\n",
    "\n",
    "# ====================\n",
    "# MEMORY MANAGEMENT\n",
    "# ====================\n",
    "def limit_memory_growth():\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(\n",
    "            tf.config.list_physical_devices('CPU')[0],\n",
    "            [tf.config.LogicalDeviceConfiguration(memory_limit=4096)]\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# ====================\n",
    "# LEARNING RATE SCHEDULER\n",
    "# ====================\n",
    "def cosine_decay_with_warmup(epoch, total_epochs, warmup_epochs=2):\n",
    "    if epoch < warmup_epochs:\n",
    "        return INITIAL_LR * ((epoch + 1) / warmup_epochs)\n",
    "    \n",
    "    progress = (epoch - warmup_epochs) / (total_epochs - warmup_epochs)\n",
    "    return INITIAL_LR * (0.5 * (1 + np.cos(np.pi * progress)) + 0.1)\n",
    "\n",
    "# ====================\n",
    "# IMAGE PREPROCESSING\n",
    "# ====================\n",
    "def enhance_mammogram(img):\n",
    "    p1, p99 = np.percentile(img, (1, 99))\n",
    "    img = np.clip(img, p1, p99)\n",
    "    img = ((img - p1) / (p99 - p1) * 255).astype(np.uint8)\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    img = clahe.apply(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def preprocess_dicom(file_path):\n",
    "    try:\n",
    "        dicom = pydicom.dcmread(file_path, force=True)\n",
    "        img = dicom.pixel_array.astype(np.float32)\n",
    "        \n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        img = enhance_mammogram(img)\n",
    "        img = (img.astype(np.float32) - 127.5) / 127.5\n",
    "        img = np.stack([img] * 3, axis=-1)\n",
    "        \n",
    "        return img\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing DICOM {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ====================\n",
    "# DATA AUGMENTATION\n",
    "# ====================\n",
    "def augment_image(img):\n",
    "    if np.random.random() > 0.5:\n",
    "        img = cv2.flip(img, 1)\n",
    "    \n",
    "    if np.random.random() > 0.5:\n",
    "        angle = np.random.uniform(-10, 10)\n",
    "        M = cv2.getRotationMatrix2D((IMG_SIZE//2, IMG_SIZE//2), angle, 1)\n",
    "        img = cv2.warpAffine(img, M, (IMG_SIZE, IMG_SIZE))\n",
    "    \n",
    "    if np.random.random() > 0.5:\n",
    "        img = img * np.random.uniform(0.8, 1.2)\n",
    "        img = np.clip(img, -1, 1)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# ====================\n",
    "# DATA GENERATOR\n",
    "# ====================\n",
    "class EnhancedGenerator(Sequence):\n",
    "    def __init__(self, file_paths, labels, batch_size, augment=False, shuffle=True):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augment\n",
    "        self.shuffle = shuffle\n",
    "        self.cache = {}\n",
    "        self.indices = np.arange(len(self.file_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.file_paths) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "        if len(self.cache) > 100:\n",
    "            keys_to_remove = np.random.choice(list(self.cache.keys()), \n",
    "                                            size=len(self.cache)//2, \n",
    "                                            replace=False)\n",
    "            for k in keys_to_remove:\n",
    "                del self.cache[k]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * self.batch_size\n",
    "        end_idx = min((idx + 1) * self.batch_size, len(self.file_paths))\n",
    "        batch_indices = self.indices[start_idx:end_idx]\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in batch_indices:\n",
    "            path = self.file_paths[i]\n",
    "            \n",
    "            if path in self.cache:\n",
    "                img = self.cache[path].copy()\n",
    "            else:\n",
    "                img = preprocess_dicom(path)\n",
    "                if len(self.cache) < 100:\n",
    "                    self.cache[path] = img.copy()\n",
    "            \n",
    "            if img is not None:\n",
    "                if self.augment:\n",
    "                    img = augment_image(img)\n",
    "                images.append(img)\n",
    "                labels.append(self.labels[i])\n",
    "        \n",
    "        if not images:\n",
    "            return self.__getitem__((idx + 1) % self.__len__())\n",
    "        \n",
    "        return np.array(images), tf.keras.utils.to_categorical(labels, num_classes=3)\n",
    "\n",
    "# ====================\n",
    "# MODEL ARCHITECTURE\n",
    "# ====================\n",
    "def build_optimized_model(img_size=224):\n",
    "    regularizer = tf.keras.regularizers.l2(WEIGHT_DECAY)\n",
    "    \n",
    "    base_model = MobileNetV3Small(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(img_size, img_size, 3),\n",
    "        include_preprocessing=False\n",
    "    )\n",
    "    \n",
    "    # Unfreeze more layers for better feature extraction\n",
    "    for layer in base_model.layers[:-50]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    inputs = layers.Input(shape=(img_size, img_size, 3))\n",
    "    x = base_model(inputs)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "    \n",
    "    # Simplified architecture with stronger regularization\n",
    "    x = layers.Dense(512, kernel_regularizer=regularizer, bias_regularizer=regularizer)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    x = layers.Dense(256, kernel_regularizer=regularizer, bias_regularizer=regularizer)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    outputs = layers.Dense(3, activation='softmax', kernel_regularizer=regularizer)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# ====================\n",
    "# TRAINING MONITOR\n",
    "# ====================\n",
    "class TrainingMonitor(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logger.info(\n",
    "            f\"Epoch {epoch + 1} - \"\n",
    "            f\"train_acc: {logs.get('accuracy', 0):.4f}, \"\n",
    "            f\"val_acc: {logs.get('val_accuracy', 0):.4f}, \"\n",
    "            f\"train_loss: {logs.get('loss', 0):.4f}, \"\n",
    "            f\"val_loss: {logs.get('val_loss', 0):.4f}\"\n",
    "        )\n",
    "\n",
    "# ====================\n",
    "# MAIN TRAINING SCRIPT\n",
    "# ====================\n",
    "def main():\n",
    "    limit_memory_growth()\n",
    "    \n",
    "    logger.info(\"Loading data...\")\n",
    "    balanced_data = pd.read_pickle(NOTEBOOK_DIRECTORY)\n",
    "    \n",
    "    filtered_data = balanced_data[\n",
    "        ['image_file_path_dicom', 'pathology', 'abnormality_type', \n",
    "         'left_or_right_breast', 'image_view']\n",
    "    ].dropna()\n",
    "    \n",
    "    label_mapping = {'BENIGN_WITHOUT_CALLBACK': 0, 'BENIGN': 1, 'MALIGNANT': 2}\n",
    "    filtered_data['label'] = filtered_data['pathology'].map(label_mapping)\n",
    "    \n",
    "    train_data, val_data = train_test_split(\n",
    "        filtered_data, \n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        stratify=filtered_data['label']\n",
    "    )\n",
    "    \n",
    "    gen_train = EnhancedGenerator(\n",
    "        train_data['image_file_path_dicom'].tolist(),\n",
    "        train_data['label'].tolist(),\n",
    "        BATCH_SIZE,\n",
    "        augment=True,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    gen_val = EnhancedGenerator(\n",
    "        val_data['image_file_path_dicom'].tolist(),\n",
    "        val_data['label'].tolist(),\n",
    "        BATCH_SIZE,\n",
    "        augment=False,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    logger.info(\"Building model...\")\n",
    "    model = build_optimized_model(IMG_SIZE)\n",
    "    \n",
    "    # Use legacy optimizer for M1 Mac without weight_decay\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(\n",
    "        learning_rate=INITIAL_LR,\n",
    "        clipnorm=1.0\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            mode='max',\n",
    "            min_delta=0.001\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_accuracy',\n",
    "            factor=0.7,\n",
    "            patience=5,\n",
    "            verbose=1,\n",
    "            mode='max',\n",
    "            min_delta=0.001\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='best_model.keras',\n",
    "            monitor='val_accuracy',\n",
    "            save_weights_only=True,\n",
    "            mode='max'\n",
    "        ),\n",
    "        TrainingMonitor(),\n",
    "        tf.keras.callbacks.LearningRateScheduler(\n",
    "            lambda epoch: cosine_decay_with_warmup(epoch, EPOCHS_INITIAL)\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    logger.info(\"Starting training...\")\n",
    "    history = model.fit(\n",
    "        gen_train,\n",
    "        validation_data=gen_val,\n",
    "        epochs=EPOCHS_INITIAL,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    logger.info(\"Saving model...\")\n",
    "    model.save('final_model.keras')\n",
    "    \n",
    "    return history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 17:32:48,535 - Loading data...\n",
      "2025-01-29 17:32:48,581 - Building model...\n",
      "2025-01-29 17:32:49,335 - Starting training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.2112 - accuracy: 0.4723"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 17:36:23,341 - Epoch 1 - train_acc: 0.4723, val_acc: 0.4526, train_loss: 1.2112, val_loss: 1.1518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 207s 4s/step - loss: 1.2112 - accuracy: 0.4723 - val_loss: 1.1518 - val_accuracy: 0.4526 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.9091 - accuracy: 0.5910"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 17:38:42,784 - Epoch 2 - train_acc: 0.5910, val_acc: 0.4737, train_loss: 0.9091, val_loss: 1.1869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 139s 3s/step - loss: 0.9091 - accuracy: 0.5910 - val_loss: 1.1869 - val_accuracy: 0.4737 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7791 - accuracy: 0.6807"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 17:41:05,055 - Epoch 3 - train_acc: 0.6807, val_acc: 0.4947, train_loss: 0.7791, val_loss: 1.1380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 142s 3s/step - loss: 0.7791 - accuracy: 0.6807 - val_loss: 1.1380 - val_accuracy: 0.4947 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7096 - accuracy: 0.6939"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 17:43:26,891 - Epoch 4 - train_acc: 0.6939, val_acc: 0.4842, train_loss: 0.7096, val_loss: 1.1752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 142s 3s/step - loss: 0.7096 - accuracy: 0.6939 - val_loss: 1.1752 - val_accuracy: 0.4842 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6443 - accuracy: 0.7480"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 17:45:52,989 - Epoch 5 - train_acc: 0.7480, val_acc: 0.5211, train_loss: 0.6443, val_loss: 1.1138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 146s 3s/step - loss: 0.6443 - accuracy: 0.7480 - val_loss: 1.1138 - val_accuracy: 0.5211 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5571 - accuracy: 0.7823"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 17:48:15,577 - Epoch 6 - train_acc: 0.7823, val_acc: 0.5684, train_loss: 0.5571, val_loss: 1.0677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 143s 3s/step - loss: 0.5571 - accuracy: 0.7823 - val_loss: 1.0677 - val_accuracy: 0.5684 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4973 - accuracy: 0.8047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 17:50:35,500 - Epoch 7 - train_acc: 0.8047, val_acc: 0.5947, train_loss: 0.4973, val_loss: 1.0366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 140s 3s/step - loss: 0.4973 - accuracy: 0.8047 - val_loss: 1.0366 - val_accuracy: 0.5947 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5201 - accuracy: 0.8087"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 17:53:00,116 - Epoch 8 - train_acc: 0.8087, val_acc: 0.5947, train_loss: 0.5201, val_loss: 1.0474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 145s 3s/step - loss: 0.5201 - accuracy: 0.8087 - val_loss: 1.0474 - val_accuracy: 0.5947 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4318 - accuracy: 0.8391"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 17:55:23,102 - Epoch 9 - train_acc: 0.8391, val_acc: 0.6000, train_loss: 0.4318, val_loss: 1.0008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 143s 3s/step - loss: 0.4318 - accuracy: 0.8391 - val_loss: 1.0008 - val_accuracy: 0.6000 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4303 - accuracy: 0.8443"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 17:57:39,192 - Epoch 10 - train_acc: 0.8443, val_acc: 0.5947, train_loss: 0.4303, val_loss: 0.9784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 136s 3s/step - loss: 0.4303 - accuracy: 0.8443 - val_loss: 0.9784 - val_accuracy: 0.5947 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4097 - accuracy: 0.8562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:00:01,729 - Epoch 11 - train_acc: 0.8562, val_acc: 0.6000, train_loss: 0.4097, val_loss: 0.9495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 143s 3s/step - loss: 0.4097 - accuracy: 0.8562 - val_loss: 0.9495 - val_accuracy: 0.6000 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3883 - accuracy: 0.8641"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:02:20,769 - Epoch 12 - train_acc: 0.8641, val_acc: 0.6526, train_loss: 0.3883, val_loss: 0.9134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 139s 3s/step - loss: 0.3883 - accuracy: 0.8641 - val_loss: 0.9134 - val_accuracy: 0.6526 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3674 - accuracy: 0.8747"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:04:46,059 - Epoch 13 - train_acc: 0.8747, val_acc: 0.6526, train_loss: 0.3674, val_loss: 0.9287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 145s 3s/step - loss: 0.3674 - accuracy: 0.8747 - val_loss: 0.9287 - val_accuracy: 0.6526 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3205 - accuracy: 0.8839"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:07:03,059 - Epoch 14 - train_acc: 0.8839, val_acc: 0.6158, train_loss: 0.3205, val_loss: 1.0339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 137s 3s/step - loss: 0.3205 - accuracy: 0.8839 - val_loss: 1.0339 - val_accuracy: 0.6158 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3469 - accuracy: 0.8786"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:09:27,452 - Epoch 15 - train_acc: 0.8786, val_acc: 0.6579, train_loss: 0.3469, val_loss: 0.9602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 144s 3s/step - loss: 0.3469 - accuracy: 0.8786 - val_loss: 0.9602 - val_accuracy: 0.6579 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2776 - accuracy: 0.9077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:11:48,653 - Epoch 16 - train_acc: 0.9077, val_acc: 0.6789, train_loss: 0.2776, val_loss: 0.9386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 141s 3s/step - loss: 0.2776 - accuracy: 0.9077 - val_loss: 0.9386 - val_accuracy: 0.6789 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.9248"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:14:06,462 - Epoch 17 - train_acc: 0.9248, val_acc: 0.6947, train_loss: 0.2611, val_loss: 0.8714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 138s 3s/step - loss: 0.2611 - accuracy: 0.9248 - val_loss: 0.8714 - val_accuracy: 0.6947 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2828 - accuracy: 0.9011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:16:44,031 - Epoch 18 - train_acc: 0.9011, val_acc: 0.6737, train_loss: 0.2828, val_loss: 0.9229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 158s 3s/step - loss: 0.2828 - accuracy: 0.9011 - val_loss: 0.9229 - val_accuracy: 0.6737 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2633 - accuracy: 0.9169"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:19:14,502 - Epoch 19 - train_acc: 0.9169, val_acc: 0.6474, train_loss: 0.2633, val_loss: 1.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 150s 3s/step - loss: 0.2633 - accuracy: 0.9169 - val_loss: 1.0156 - val_accuracy: 0.6474 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2582 - accuracy: 0.9077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:21:31,508 - Epoch 20 - train_acc: 0.9077, val_acc: 0.6684, train_loss: 0.2582, val_loss: 1.0433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 137s 3s/step - loss: 0.2582 - accuracy: 0.9077 - val_loss: 1.0433 - val_accuracy: 0.6684 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2156 - accuracy: 0.9327"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:23:56,290 - Epoch 21 - train_acc: 0.9327, val_acc: 0.7105, train_loss: 0.2156, val_loss: 0.9046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 145s 3s/step - loss: 0.2156 - accuracy: 0.9327 - val_loss: 0.9046 - val_accuracy: 0.7105 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2333 - accuracy: 0.9288"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:26:22,520 - Epoch 22 - train_acc: 0.9288, val_acc: 0.7579, train_loss: 0.2333, val_loss: 0.7510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 146s 3s/step - loss: 0.2333 - accuracy: 0.9288 - val_loss: 0.7510 - val_accuracy: 0.7579 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2061 - accuracy: 0.9367"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:28:43,585 - Epoch 23 - train_acc: 0.9367, val_acc: 0.7579, train_loss: 0.2061, val_loss: 0.7839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 141s 3s/step - loss: 0.2061 - accuracy: 0.9367 - val_loss: 0.7839 - val_accuracy: 0.7579 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2067 - accuracy: 0.9354"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:31:06,732 - Epoch 24 - train_acc: 0.9354, val_acc: 0.7579, train_loss: 0.2067, val_loss: 0.7063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 143s 3s/step - loss: 0.2067 - accuracy: 0.9354 - val_loss: 0.7063 - val_accuracy: 0.7579 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.1949 - accuracy: 0.9472"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:33:28,142 - Epoch 25 - train_acc: 0.9472, val_acc: 0.8053, train_loss: 0.1949, val_loss: 0.6801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 141s 3s/step - loss: 0.1949 - accuracy: 0.9472 - val_loss: 0.6801 - val_accuracy: 0.8053 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.1896 - accuracy: 0.9459"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:35:48,600 - Epoch 26 - train_acc: 0.9459, val_acc: 0.7842, train_loss: 0.1896, val_loss: 0.7093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 140s 3s/step - loss: 0.1896 - accuracy: 0.9459 - val_loss: 0.7093 - val_accuracy: 0.7842 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.1853 - accuracy: 0.9393"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:38:19,461 - Epoch 27 - train_acc: 0.9393, val_acc: 0.7895, train_loss: 0.1853, val_loss: 0.7237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 151s 3s/step - loss: 0.1853 - accuracy: 0.9393 - val_loss: 0.7237 - val_accuracy: 0.7895 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.1525 - accuracy: 0.9657"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:40:42,598 - Epoch 28 - train_acc: 0.9657, val_acc: 0.8211, train_loss: 0.1525, val_loss: 0.6844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 143s 3s/step - loss: 0.1525 - accuracy: 0.9657 - val_loss: 0.6844 - val_accuracy: 0.8211 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.1865 - accuracy: 0.9472"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:43:04,847 - Epoch 29 - train_acc: 0.9472, val_acc: 0.8421, train_loss: 0.1865, val_loss: 0.6093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 142s 3s/step - loss: 0.1865 - accuracy: 0.9472 - val_loss: 0.6093 - val_accuracy: 0.8421 - lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.1741 - accuracy: 0.9525"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:45:19,987 - Epoch 30 - train_acc: 0.9525, val_acc: 0.8526, train_loss: 0.1741, val_loss: 0.6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 135s 3s/step - loss: 0.1741 - accuracy: 0.9525 - val_loss: 0.6500 - val_accuracy: 0.8526 - lr: 1.0000e-04\n",
      "Epoch 31/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.1705 - accuracy: 0.9459"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:47:45,018 - Epoch 31 - train_acc: 0.9459, val_acc: 0.8526, train_loss: 0.1705, val_loss: 0.6028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 145s 3s/step - loss: 0.1705 - accuracy: 0.9459 - val_loss: 0.6028 - val_accuracy: 0.8526 - lr: 1.0000e-04\n",
      "Epoch 32/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.1667 - accuracy: 0.9525"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:50:06,566 - Epoch 32 - train_acc: 0.9525, val_acc: 0.8842, train_loss: 0.1667, val_loss: 0.5832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 142s 3s/step - loss: 0.1667 - accuracy: 0.9525 - val_loss: 0.5832 - val_accuracy: 0.8842 - lr: 1.0000e-04\n",
      "Epoch 33/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.1545 - accuracy: 0.9617"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:52:37,493 - Epoch 33 - train_acc: 0.9617, val_acc: 0.8947, train_loss: 0.1545, val_loss: 0.5924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 151s 3s/step - loss: 0.1545 - accuracy: 0.9617 - val_loss: 0.5924 - val_accuracy: 0.8947 - lr: 1.0000e-04\n",
      "Epoch 34/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.1764 - accuracy: 0.9565"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:55:03,343 - Epoch 34 - train_acc: 0.9565, val_acc: 0.8579, train_loss: 0.1764, val_loss: 0.6130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 146s 3s/step - loss: 0.1764 - accuracy: 0.9565 - val_loss: 0.6130 - val_accuracy: 0.8579 - lr: 1.0000e-04\n",
      "Epoch 35/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.1568 - accuracy: 0.9591"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:57:25,730 - Epoch 35 - train_acc: 0.9591, val_acc: 0.8684, train_loss: 0.1568, val_loss: 0.5741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 142s 3s/step - loss: 0.1568 - accuracy: 0.9591 - val_loss: 0.5741 - val_accuracy: 0.8684 - lr: 1.0000e-04\n",
      "Epoch 36/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.9604"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:59:53,390 - Epoch 36 - train_acc: 0.9604, val_acc: 0.9000, train_loss: 0.1485, val_loss: 0.5341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 148s 3s/step - loss: 0.1485 - accuracy: 0.9604 - val_loss: 0.5341 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
      "Epoch 37/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.1480 - accuracy: 0.9617"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 19:02:13,459 - Epoch 37 - train_acc: 0.9617, val_acc: 0.9000, train_loss: 0.1480, val_loss: 0.5468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 140s 3s/step - loss: 0.1480 - accuracy: 0.9617 - val_loss: 0.5468 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
      "Epoch 38/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.9815"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 19:04:40,906 - Epoch 38 - train_acc: 0.9815, val_acc: 0.9000, train_loss: 0.1074, val_loss: 0.5374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 147s 3s/step - loss: 0.1074 - accuracy: 0.9815 - val_loss: 0.5374 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
      "Epoch 39/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.1511 - accuracy: 0.9565"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 19:07:05,969 - Epoch 39 - train_acc: 0.9565, val_acc: 0.9000, train_loss: 0.1511, val_loss: 0.5684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 145s 3s/step - loss: 0.1511 - accuracy: 0.9565 - val_loss: 0.5684 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
      "Epoch 40/40\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.9710"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 19:09:32,054 - Epoch 40 - train_acc: 0.9710, val_acc: 0.9105, train_loss: 0.1236, val_loss: 0.5611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 146s 3s/step - loss: 0.1236 - accuracy: 0.9710 - val_loss: 0.5611 - val_accuracy: 0.9105 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 19:09:32,060 - Saving model...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# ====================\n",
    "# OPTIMIZED PARAMETERS\n",
    "# ====================\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16  # Increased for better stability\n",
    "EPOCHS_INITIAL = 40\n",
    "INITIAL_LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# File path\n",
    "NOTEBOOK_DIRECTORY = \"/Users/dtilm/Desktop/P1-Classification/notebook/balanced_data.pkl\"\n",
    "\n",
    "# ====================\n",
    "# SAFE DATA LOADING\n",
    "# ====================\n",
    "def load_data_safely():\n",
    "    \"\"\"Safely load pickle data with error handling\"\"\"\n",
    "    try:\n",
    "        logger.info(\"Loading data...\")\n",
    "        return pd.read_pickle(NOTEBOOK_DIRECTORY)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading pickle: {e}\")\n",
    "        raise\n",
    "\n",
    "# ====================\n",
    "# IMAGE PREPROCESSING\n",
    "# ====================\n",
    "def enhance_mammogram(img):\n",
    "    \"\"\"Enhanced mammogram preprocessing\"\"\"\n",
    "    p1, p99 = np.percentile(img, (1, 99))\n",
    "    img = np.clip(img, p1, p99)\n",
    "    img = ((img - p1) / (p99 - p1) * 255).astype(np.uint8)\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    img = clahe.apply(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def preprocess_dicom(file_path):\n",
    "    \"\"\"Optimized DICOM preprocessing\"\"\"\n",
    "    try:\n",
    "        dicom = pydicom.dcmread(file_path, force=True)\n",
    "        img = dicom.pixel_array.astype(np.float32)\n",
    "        \n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        img = enhance_mammogram(img)\n",
    "        img = (img.astype(np.float32) - 127.5) / 127.5\n",
    "        img = np.stack([img] * 3, axis=-1)\n",
    "        \n",
    "        return img\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing DICOM {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ====================\n",
    "# DATA AUGMENTATION\n",
    "# ====================\n",
    "def augment_image(img):\n",
    "    \"\"\"Optimized data augmentation\"\"\"\n",
    "    if np.random.random() > 0.5:\n",
    "        img = cv2.flip(img, 1)\n",
    "    \n",
    "    if np.random.random() > 0.5:\n",
    "        angle = np.random.uniform(-10, 10)\n",
    "        M = cv2.getRotationMatrix2D((IMG_SIZE//2, IMG_SIZE//2), angle, 1)\n",
    "        img = cv2.warpAffine(img, M, (IMG_SIZE, IMG_SIZE))\n",
    "    \n",
    "    if np.random.random() > 0.5:\n",
    "        img = img * np.random.uniform(0.8, 1.2)\n",
    "        img = np.clip(img, -1, 1)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# ====================\n",
    "# DATA GENERATOR\n",
    "# ====================\n",
    "class EnhancedGenerator(Sequence):\n",
    "    def __init__(self, file_paths, labels, batch_size, augment=False, shuffle=True):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augment\n",
    "        self.shuffle = shuffle\n",
    "        self.cache = {}\n",
    "        self.indices = np.arange(len(self.file_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.file_paths) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "        if len(self.cache) > 100:  # Clear cache periodically\n",
    "            self.cache.clear()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * self.batch_size\n",
    "        end_idx = min((idx + 1) * self.batch_size, len(self.file_paths))\n",
    "        batch_indices = self.indices[start_idx:end_idx]\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in batch_indices:\n",
    "            path = self.file_paths[i]\n",
    "            if path in self.cache:\n",
    "                img = self.cache[path].copy()\n",
    "            else:\n",
    "                img = preprocess_dicom(path)\n",
    "                if len(self.cache) < 100:  # Limit cache size\n",
    "                    self.cache[path] = img.copy()\n",
    "            \n",
    "            if img is not None:\n",
    "                if self.augment:\n",
    "                    img = augment_image(img)\n",
    "                images.append(img)\n",
    "                labels.append(self.labels[i])\n",
    "        \n",
    "        if not images:\n",
    "            return self.__getitem__((idx + 1) % self.__len__())\n",
    "        \n",
    "        return np.array(images), tf.keras.utils.to_categorical(labels, num_classes=3)\n",
    "\n",
    "# ====================\n",
    "# MODEL ARCHITECTURE\n",
    "# ====================\n",
    "def build_optimized_model(img_size=224):\n",
    "    \"\"\"Optimized model architecture\"\"\"\n",
    "    regularizer = tf.keras.regularizers.l2(WEIGHT_DECAY)\n",
    "    \n",
    "    base_model = MobileNetV3Small(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(img_size, img_size, 3),\n",
    "        include_preprocessing=False\n",
    "    )\n",
    "    \n",
    "    # Freeze early layers\n",
    "    for layer in base_model.layers[:-30]:  # Only train the last 30 layers\n",
    "        layer.trainable = False\n",
    "    \n",
    "    inputs = layers.Input(shape=(img_size, img_size, 3))\n",
    "    x = base_model(inputs)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "    \n",
    "    x = layers.Dense(256, kernel_regularizer=regularizer)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    outputs = layers.Dense(3, activation='softmax')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# ====================\n",
    "# TRAINING MONITOR\n",
    "# ====================\n",
    "class TrainingMonitor(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logger.info(\n",
    "            f\"Epoch {epoch + 1} - \"\n",
    "            f\"train_acc: {logs.get('accuracy', 0):.4f}, \"\n",
    "            f\"val_acc: {logs.get('val_accuracy', 0):.4f}, \"\n",
    "            f\"train_loss: {logs.get('loss', 0):.4f}, \"\n",
    "            f\"val_loss: {logs.get('val_loss', 0):.4f}\"\n",
    "        )\n",
    "\n",
    "# ====================\n",
    "# MAIN TRAINING SCRIPT\n",
    "# ====================\n",
    "def main():\n",
    "    # Load data\n",
    "    balanced_data = load_data_safely()\n",
    "    \n",
    "    filtered_data = balanced_data[\n",
    "        ['image_file_path_dicom', 'pathology', 'abnormality_type', \n",
    "         'left_or_right_breast', 'image_view']\n",
    "    ].dropna()\n",
    "    \n",
    "    label_mapping = {'BENIGN_WITHOUT_CALLBACK': 0, 'BENIGN': 1, 'MALIGNANT': 2}\n",
    "    filtered_data['label'] = filtered_data['pathology'].map(label_mapping)\n",
    "    \n",
    "    # Data split\n",
    "    train_data, val_data = train_test_split(\n",
    "        filtered_data, \n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        stratify=filtered_data['label']\n",
    "    )\n",
    "    \n",
    "    # Create generators\n",
    "    gen_train = EnhancedGenerator(\n",
    "        train_data['image_file_path_dicom'].tolist(),\n",
    "        train_data['label'].tolist(),\n",
    "        BATCH_SIZE,\n",
    "        augment=True,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    gen_val = EnhancedGenerator(\n",
    "        val_data['image_file_path_dicom'].tolist(),\n",
    "        val_data['label'].tolist(),\n",
    "        BATCH_SIZE,\n",
    "        augment=False,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Build and compile model\n",
    "    logger.info(\"Building model...\")\n",
    "    model = build_optimized_model(IMG_SIZE)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(\n",
    "        learning_rate=INITIAL_LR,\n",
    "        clipnorm=1.0\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            mode='max',\n",
    "            min_delta=0.001\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_accuracy',\n",
    "            factor=0.7,\n",
    "            patience=5,\n",
    "            verbose=1,\n",
    "            mode='max',\n",
    "            min_delta=0.001\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='best_model.keras',\n",
    "            monitor='val_accuracy',\n",
    "            save_weights_only=True,\n",
    "            mode='max'\n",
    "        ),\n",
    "        TrainingMonitor()\n",
    "    ]\n",
    "    \n",
    "    # Train\n",
    "    logger.info(\"Starting training...\")\n",
    "    history = model.fit(\n",
    "        gen_train,\n",
    "        validation_data=gen_val,\n",
    "        epochs=EPOCHS_INITIAL,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Save model\n",
    "    logger.info(\"Saving model...\")\n",
    "    model.save('final_model.keras')\n",
    "    \n",
    "    return history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
